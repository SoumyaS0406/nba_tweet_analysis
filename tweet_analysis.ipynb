{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.daniweb.com/programming/software-development/threads/141128/read-multiple-files<br>\n",
    "http://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path ='C:\\\\Users\\\\Rhea\\\\Documents\\\\GitHubF\\\\ProLytics\\\\tweet_analysis\\\\player'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(string_in):\n",
    "    #remove all chars except @ _ alphanumerics\n",
    "    string_in=string_in.replace('&amp','')\n",
    "    regex_punct = re.compile('[^A-Za-z0-9 _@#]')\n",
    "    string_out=regex_punct.sub(u'', string_in)\n",
    "    return string_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_callout_url_hashtags(string_in):\n",
    "    list_rem=[]\n",
    "    list_rem.extend([w for w in string_in.split(' ') if re.search('@[A-Za-z0-9_]+',w) and  w.startswith('@')])\n",
    "    list_rem.extend([w for w in string_in.split(' ') if re.search('#[A-Za-z0-9_]+',w) and  w.startswith('#')])\n",
    "    list_rem.extend([w for w in string_in.split(' ') if w.startswith('http')])\n",
    "    #print(list_rem)\n",
    "    \n",
    "    string_out=string_in\n",
    "    for word in list_rem:\n",
    "        if word in string_out.split(' '):\n",
    "            string_out=string_out.replace(word,\"\")\n",
    "                        \n",
    "    #string_out=[string_in.replace(word,\"\") for word in string_in.split(' ') if word in list_rem]\n",
    "    return string_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(string_in):\n",
    "    analysis=TextBlob(doc)\n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dictionary with key as \"player twitter handle\" and value as dataframe with twitter data for corresponding player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_dict={}\n",
    "# use join for multi platform compatibility\n",
    "for infile in glob.glob(os.path.join(path, '*.csv')):\n",
    "    \n",
    "    # infile stores the complete path of the file\n",
    "    ###print(\"Current File Being Processed is:  \" + infile)\n",
    "    #use split to seperate the path and name of the file\n",
    "    (PATH, FILENAME) = os.path.split(infile)\n",
    "    #use splitext() to seperate name of the file and the extension\n",
    "    (ShortName, Extension) = os.path.splitext(FILENAME)\n",
    "    player_tw_hand=ShortName.split('_tweets')[0]\n",
    "    ###print(player_name)\n",
    "    dict_temp={}\n",
    "    df = pd.read_csv(infile)\n",
    "    df.dropna(inplace=True)\n",
    "    dict_temp[player_tw_hand]=df\n",
    "    tweet_dict.update(dict_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Callouts for every player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_tw_hand is ::alexlen\n"
     ]
    }
   ],
   "source": [
    "callout_dict={}\n",
    "for player_tw_hand, player_tweets in tweet_dict.items():\n",
    "    print('player_tw_hand is ::'+ player_tw_hand)\n",
    "    callout_list=[]\n",
    "    hashtag_list=[]\n",
    "    url_list=[]\n",
    "    for doc in player_tweets['text'].tolist():\n",
    "        url_list.extend([w for w in doc.split(' ') if w.startswith('http')])\n",
    "        doc=remove_punctuation(doc)\n",
    "        callout_list.extend([w for w in doc.split(' ') if re.search('@[A-Za-z0-9_]+',w) and  w.startswith('@')])\n",
    "        hashtag_list.extend([w for w in doc.split(' ') if re.search('#[A-Za-z0-9_]+',w) and  w.startswith('#')])\n",
    "        \n",
    "        \n",
    "        #print('Player :: ' +(Counter(callout_list).most_common(10)))\n",
    "        #print('Player :: ' +(Counter(hashtag_list).most_common(10)))\n",
    "        \n",
    "        dict1={}\n",
    "        dict_temp1= dict((i, callout_list.count(i)) for i in set(callout_list))\n",
    "        dict_temp1 = sorted(dict_temp1.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        dict_temp2= dict((i, hashtag_list.count(i)) for i in set(hashtag_list))\n",
    "        dict_temp2 = sorted(dict_temp2.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        dict_temp3= dict((i, url_list.count(i)) for i in set(url_list))\n",
    "        dict_temp3 = sorted(dict_temp3.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        dict1[player_tw_hand]=dict_temp1,dict_temp2,dict_temp3\n",
    "        callout_dict.update(dict1)\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(callout_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print([[x,callout_list.count(x)] for x in set(callout_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# Counter(list1).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callout_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@alexlen', 31), ('@Suns', 10), ('@lenfoundation', 8), ('@CoachTurgeon', 5), ('@PhoenixParks', 5), ('@JohnnyS7ORM', 4), ('@mowilkerson', 4), ('@umterps', 3), ('@mike_sig', 3), ('@SportsIntGroup', 3), ('@TerrapinHoops', 3), ('@cwiestling', 2), ('@NBA', 2), ('@alexlens', 2), ('@APS_Rich', 2), ('@Dez32Wells', 2), ('@ZachingVsCancer', 2), ('@Blanetrain412', 2), ('@WashWizards', 2), ('@AlexVinogradoff', 2), ('@widya_nurul', 2), ('@riguy22', 2), ('@nba', 2), ('@gmoneyaz1983', 2), ('@Anosike_1', 1), ('@vinnie_vici', 1), ('@Joseph_flores20', 1), ('@Goh_mann', 1), ('@fibber77', 1), ('@Dyamon20', 1), ('@Suns4kids', 1), ('@noahmcook', 1), ('@tifahthompson', 1), ('@AlexLen', 1), ('@notthefakeSVP', 1), ('@TheRealJoe_D', 1), ('@Joshwon23', 1), ('@Iceman__34', 1), ('@beeekayballla', 1), ('@BMSS_JonRadow', 1), ('@cpasion8', 1), ('@AndrewJayOlsen', 1), ('@JacobPadilla_', 1), ('@TorreySmithWR', 1), ('@Z', 1), ('@IRodriguez_24', 1), ('@ZLeds', 1), ('@camillasaguin', 1), ('@Big_Tah47', 1), ('@Goran_Dragic', 1), ('@JacobRathjen', 1), ('@alexlenbasketballcamps', 1), ('@Michael_Long14', 1), ('@Playbacker2014', 1), ('@borntotailor', 1), ('@TaParkin', 1), ('@LiamMorales6', 1), ('@d_t_nguyen86', 1), ('@umdwbb', 1), ('@BrawadisNBA', 1), ('@eddiepuig', 1), ('@SpencerReed80', 1), ('@MaxArnheiter17', 1), ('@ihasan_', 1), ('@angelisprattas', 1), ('@Keefmorris', 1), ('@Espo', 1), ('@TheBeanSupreme', 1), ('@__AntC', 1), ('@Hudsonwife16', 1), ('@MGortat', 1), ('@sahmad95', 1), ('@spotz777', 1), ('@basketballtalk', 1), ('@kbbatman22', 1), ('@SLAMonline', 1), ('@Ty24Dbacks', 1), ('@BCSisaJoke', 1), ('@TichaPenicheiro', 1), ('@JackShapiro1', 1), ('@TTwersky', 1), ('@stancehoops', 1), ('@MSemerad13', 1), ('@raechen6', 1), ('@9nicknovak', 1), ('@ElChosenJuan94', 1), ('@kyletkerch', 1), ('@frysfoodstores', 1), ('@guppnoy831', 1), ('@VICESports', 1), ('@shawnemerriman', 1), ('@TavonWilson27', 1), ('@KidBuxton', 1), ('@chloifornia', 1), ('@WashWizards@Suns', 1), ('@DaveDoran88', 1), ('@Paul__Dawkins', 1), ('@TheDerrickHolt', 1), ('@adamisbell', 1), ('@FrysFoodStores', 1), ('@CashOutFan', 1), ('@pfeiffz', 1), ('@EatUmUpPhoto', 1), ('@JaredOrnoski', 1), ('@PHXPolice', 1), ('@Diamond_Stone33', 1), ('@bostonmarket', 1), ('@shell4410', 1), ('@KateWGallego', 1), ('@Gregg_Bach', 1), ('@RenegadeMovemnt', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(callout_dict.get('alexlen')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#WeArePHX', 33), ('#AlexLenTrivia', 10), ('#Terpnation', 4), ('#feartheturtle', 3), ('#SunsNation', 3), ('#PHX4Jared', 3), ('#sigfam', 2), ('#SunsLottery', 2), ('#SIGFam', 2), ('#sunsnation', 2), ('#SIGFamRT', 2), ('#terpnation', 2), ('#MerryChristmas', 1), ('#SunsSocialNight', 1), ('#Pjfperformance', 1), ('#toonervoustosayhi', 1), ('#AlexLen', 1), ('#Terrapins', 1), ('#Gameday', 1), ('#zaching', 1), ('#Phoenix', 1), ('#SuperBowlBound', 1), ('#Day2RT', 1), ('#LetssssGoooo', 1), ('#PrayForUkraine', 1), ('#TBT', 1), ('#LenDaHandFoundation', 1), ('#TerpNation', 1), ('#thecommissh', 1), ('#sunsnationBe', 1), ('#TerpFamily', 1), ('#LendAHand', 1), ('#WeWill', 1), ('#GoMustangs', 1), ('#PatriotsNation', 1), ('#prayforukraine', 1), ('#Official', 1), ('#IGPage', 1), ('#Follow', 1), ('##LendAHand', 1), ('#Thanksgiving', 1), ('#terps', 1), ('#GAIN', 1), ('#SuperBowlXLIX', 1), ('#Day1', 1), ('#BeatWisconsin', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(callout_dict.get('alexlen')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://t.co/yz1Iou0QjZ', 1), ('https://t.co/Xh3W09NUNu', 1), ('https://t.co/GyAPtIpajo', 1), ('http://t.co/0g4…', 1), ('http://t.co/5ydUpbDUSA', 1), ('http://t.co/4K9HEwT5iT', 1), ('http://t.co/FIm66aBDRN', 1), ('https://t.co/kaQzqnf7ok', 1), ('https://t.co/0njAOWsS9l', 1), ('http:/…', 1), ('http://t.co/WTJEgSW00Y', 1), ('http://t.co/J0IHg0WQyp', 1), ('https://t.co/CxrLCVdJu6', 1), ('http://t.co/800VtDGOhB', 1), ('https://t.co/0XhNpVZjAZ', 1), ('https://t.co/XqUhnhCZ18', 1), ('https://t.co/q…', 1), ('https://t.co/Y…', 1), ('https://t.co/ZCuVb2XfoM', 1), ('https://t.co/OXLApMpong', 1), ('https://t.co/nEImoBvS4r', 1), ('http://t.co/BzaNlI5Hbf', 1), ('http://t.co/aO…', 1), ('https://t.co/qGmEgWd4iD', 1), ('https://t.co/1hNUqGpxal', 1), ('https://t.co/wm4MS1Y7vm', 1), ('http://t.co/8BxSVCA9m6', 1), ('https://t.co/XF18fxeGxA', 1), ('http://t.co/FEo0PmLBRi', 1), ('https://t.co/BJYTsH1bsY', 1), ('http://t.co/UTAu…', 1), ('https://t.co/jMFKJFFdCC', 1), ('http://t.co/xfiFyZEAay', 1), ('https://t.co/qDJKGovlln', 1), ('http://t.co/3ccommRbmg', 1), ('http://t.co/YYCE4ryNIY', 1), ('http://t.co/vGljr7lBnF', 1), ('https://t.co/CAuPwjYpVi', 1), ('http://t.co/PNj6ppmC…', 1), ('https://t.co/gIC6PT1ytB', 1), ('https://t.co/5HDrnMddtU', 1), ('https://t.co/qt1usl8A…', 1), ('http://t.co…', 1), ('https://t.co/wfmz3BpcPD', 1), ('https://t.co/TtkdMX2LeV', 1), ('https://t.co/NawqzmP1MX', 1), ('http://t.co/wKTnjxdsUP', 1), ('http://t.co/X4…', 1), ('https://t.co/GP4lozFChn', 1), ('https://t.co/OL4vpPPddy', 1), ('http://t.c…', 1), ('https://t.co/JiMq61o6PT', 1), ('https://t.co/81…', 1), ('https://t.co/sDlVtmskYL', 1), ('http://t.co/hRe3HDrfdz', 1), ('http://t.co/Dv9yJzVkZU', 1), ('https://t.co/6KV…', 1), ('https://t.co/SEXaeSWDNu', 1), ('https:…', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(callout_dict.get('alexlen')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc='dgdghdg #dddd'\n",
    "hashtag_list=[]\n",
    "hashtag_list.extend([w for w in doc.split(' ') if re.search('#[A-Za-z0-9_]+',w) and  w.startswith('#')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "We will work using tweet_dict where values correspond to twitter datasets respective to players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for player_handle, tweet_df in tweet_dict.items():\n",
    "    polarity=[]\n",
    "    for doc in tweet_df['text']:\n",
    "        doc=remove_callout_url_hashtags(doc)\n",
    "        doc=remove_punctuation(doc)\n",
    "        sent_pol=get_tweet_sentiment(doc)\n",
    "        polarity.append(sent_pol)\n",
    "    print(len(polarity), len(tweet_df['text']))\n",
    "    tweet_df['polarity']=polarity\n",
    "    #write the csv\n",
    "    tweet_df.to_csv(\"C:\\\\Users\\\\Rhea\\\\Documents\\\\GitHubF\\\\ProLytics\\\\tweet_analysis\\\\player1\\\\\"+player_handle+\"_tweets.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqq=remove_callout_url_hashtags('Gracias por el apoyo! Robinson y Manny!!! ??#Celtics https://t.co/AtZeYs5hb2')\n",
    "qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
